{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"covid19_rel_lianxiangjia\"\n",
    "data_home = \"/home/wangyucheng/workplace/notebook/research/joint_extr/raw_data\" + exp_name\n",
    "data_output_dir = \"/home/wangyucheng/workplace/notebook/research/joint_extr/ori_data\" + exp_name\n",
    "if not os.path.exists(data_output_dir):\n",
    "    os.makedirs(data_output_dir)\n",
    "    \n",
    "train_label_path = os.path.join(data_home, \"task2_train_label.json\")\n",
    "train_label = json.load(open(train_label_path, \"r\", encoding = \"utf-8\"))\n",
    "train_text_path = os.path.join(data_home, \"user_task2_train.json\")\n",
    "train_text = json.load(open(train_text_path, \"r\", encoding = \"utf-8\"))\n",
    "test_text_path = os.path.join(data_home, \"user_task2_valid.json\")\n",
    "test_text = json.load(open(test_text_path, \"r\", encoding = \"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1330 1330 570\n"
     ]
    }
   ],
   "source": [
    "print(len(train_label), len(train_text), len(test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2rel_list = {}\n",
    "for sample in train_label:\n",
    "    for k, v in sample.items():\n",
    "        assert k not in idx2rel_list\n",
    "        idx2rel_list[k] = v\n",
    "\n",
    "idx2text = {}\n",
    "for sample in train_text:\n",
    "    for k, v in sample.items():\n",
    "        assert k not in idx2text\n",
    "        idx2text[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_train_data = []\n",
    "for idx, text in idx2text.items():\n",
    "    sample = {\n",
    "        \"id\": idx,\n",
    "        \"text\": text,\n",
    "    }\n",
    "    rel_list = []\n",
    "    for rel in idx2rel_list[idx]:\n",
    "        rel_list.append({\n",
    "            \"subject\": rel[0],\n",
    "            \"predicate\": rel[1],\n",
    "            \"object\": rel[2],\n",
    "        })\n",
    "    sample[\"relation_list\"] = rel_list\n",
    "    ori_train_data.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "for sample in test_text:\n",
    "    for k, v in sample.items():\n",
    "        test_data.append({\n",
    "            \"id\": k,\n",
    "            \"text\": v,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:00<00:00, 12.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063 267\n",
      "1063 267\n",
      "1063 267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 12.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063 267\n",
      "1068 262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "seed = 2333\n",
    "k = 5\n",
    "random.seed(seed)\n",
    "random.shuffle(ori_train_data)\n",
    "valid_num = int(len(ori_train_data) * (1 / k)) + 1\n",
    "\n",
    "group_num = 0\n",
    "for start_idx in tqdm(range(0, len(ori_train_data), valid_num)):\n",
    "    end_idx = start_idx + valid_num\n",
    "    valid_data = ori_train_data[start_idx:end_idx]\n",
    "    train_data = ori_train_data[:start_idx] + ori_train_data[end_idx:]\n",
    "#     print(len(train_data), len(valid_data))\n",
    "    # ouput\n",
    "    train_data_path = os.path.join(data_output_dir, \"train_data_{}.json\".format(group_num))\n",
    "    valid_data_path = os.path.join(data_output_dir, \"valid_data_{}.json\".format(group_num))\n",
    "    json.dump(train_data, open(train_data_path, \"w\", encoding = \"utf-8\"), ensure_ascii = False)\n",
    "    json.dump(valid_data, open(valid_data_path, \"w\", encoding = \"utf-8\"), ensure_ascii = False)\n",
    "    group_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path = os.path.join(data_output_dir, \"test_data.json\")\n",
    "json.dump(test_data, open(test_data_path, \"w\", encoding = \"utf-8\"), ensure_ascii = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
